# SOME DESCRIPTIVE TITLE.
# Copyright (C)
# This file is distributed under the same license as the PEPs package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PEPs\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-11-28 20:07+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"

#: ../pep-0270.txt
msgid "Author"
msgstr "Autor"

#: ../pep-0270.txt:3
msgid "Jason Petrone <jp@demonseed.net>"
msgstr ""

#: ../pep-0270.txt
msgid "Status"
msgstr "Status"

#: ../pep-0270.txt:4
msgid "Rejected"
msgstr ""

#: ../pep-0270.txt
msgid "Type"
msgstr "Tipo"

#: ../pep-0270.txt:5
msgid "Standards Track"
msgstr ""

#: ../pep-0270.txt
msgid "Created"
msgstr "Criada em"

#: ../pep-0270.txt:7
msgid "21-Aug-2001"
msgstr ""

#: ../pep-0270.txt
msgid "Python-Version"
msgstr ""

#: ../pep-0270.txt:8
msgid "2.2"
msgstr ""

#: ../pep-0270.txt
msgid "Post-History"
msgstr "Pós-história"

#: ../pep-0270.txt:13
msgid "Notice"
msgstr ""

#: ../pep-0270.txt:15
msgid "This PEP is withdrawn by the author.  He writes:"
msgstr ""

#: ../pep-0270.txt:17
msgid ""
"Removing duplicate elements from a list is a common task, but there are only "
"two reasons I can see for making it a built-in. The first is if it could be "
"done much faster, which isn't the case.  The second is if it makes it "
"significantly easier to write code.  The introduction of ``sets.py`` "
"eliminates this situation since creating a sequence without duplicates is "
"just a matter of choosing a different data structure: a set instead of a "
"list."
msgstr ""

#: ../pep-0270.txt:26
msgid ""
"As described in :pep:`218`, sets are being added to the standard library for "
"Python 2.3."
msgstr ""

#: ../pep-0270.txt:31
msgid "Abstract"
msgstr ""

#: ../pep-0270.txt:33
msgid ""
"This PEP proposes adding a method for removing duplicate elements to the "
"list object."
msgstr ""

#: ../pep-0270.txt:38
msgid "Rationale"
msgstr ""

#: ../pep-0270.txt:40
msgid ""
"Removing duplicates from a list is a common task.  I think it is useful and "
"general enough to belong as a method in list objects. It also has potential "
"for faster execution when implemented in C, especially if optimization using "
"hashing or sorted cannot be used."
msgstr ""

#: ../pep-0270.txt:45
msgid ""
"On comp.lang.python there are many, many, posts [1]_ asking about the best "
"way to do this task.  It's a little tricky to implement optimally and it "
"would be nice to save people the trouble of figuring it out themselves."
msgstr ""

#: ../pep-0270.txt:52
msgid "Considerations"
msgstr ""

#: ../pep-0270.txt:54
msgid ""
"Tim Peters suggests trying to use a hash table, then trying to sort, and "
"finally falling back on brute force [2]_.  Should uniq maintain list order "
"at the expense of speed?"
msgstr ""

#: ../pep-0270.txt:58
msgid "Is it spelled 'uniq' or 'unique'?"
msgstr ""

#: ../pep-0270.txt:62
msgid "Reference Implementation"
msgstr ""

#: ../pep-0270.txt:64
msgid ""
"I've written the brute force version.  It's about 20 lines of code in "
"``listobject.c``.  Adding support for hash table and sorted duplicate "
"removal would only take another hour or so."
msgstr ""

#: ../pep-0270.txt:70
msgid "References"
msgstr "Referências"

#: ../pep-0270.txt:72
msgid "https://groups.google.com/forum/#!searchin/comp.lang.python/duplicates"
msgstr ""

#: ../pep-0270.txt:74
msgid ""
"Tim Peters unique() entry in the Python cookbook: http://aspn.activestate."
"com/ASPN/Cookbook/Python/Recipe/52560/index_txt"
msgstr ""

#: ../pep-0270.txt:79
msgid "Copyright"
msgstr "Copyright"

#: ../pep-0270.txt:81
msgid "This document has been placed in the public domain."
msgstr "Este documento foi colocado em domínio público."
